
# Triki (Tic-Tac-Toe) con Q-Learning

AplicaciÃ³n educativa en **Python + Streamlit** para enseÃ±ar **Aprendizaje por Refuerzo tabular** (Q-Learning) entrenando un agente que juega **Triki**.

## ğŸ§° Estructura
- `tictactoe_rl.py`: Entorno y agente Q-Learning **documentados en espaÃ±ol**.
- `streamlit_app.py`: Interfaz grÃ¡fica para **entrenar** y **jugar** contra el agente.
- `requirements.txt`: Dependencias mÃ­nimas.

## â–¶ï¸ CÃ³mo ejecutar
1. **(Opcional)** Crea y activa un entorno virtual.
2. Instala dependencias:
   ```bash
   pip install -r requirements.txt
   ```
2.1 pip install streamlit

3. Ejecuta la app:
   ```bash
   streamlit run streamlit_app.py
   ```

> **Requisitos**: Python 3.10+ (probado con 3.12).

## ğŸ® CÃ³mo se usa
- En la barra lateral:
  - Ajusta hiperparÃ¡metros `Î±`, `Î³`, `Îµ`.
  - Entrena el agente por *N* episodios (contra un oponente aleatorio).
  - Activa "Aprender durante la partida" para que el modelo **siga aprendiendo** cuando juegue contigo.
  - Guarda / carga el modelo (Q-table) a/desde un archivo JSON.
- En la vista principal:
  - Reinicia la partida o elige quiÃ©n empieza (humano/agente).
  - Haz clic en una celda para jugar.

## ğŸ§  QuÃ© aprende el agente
El agente maximiza recompensa: **+1 ganar, -1 perder, 0 empatar**.
Usa **Îµ-greedy** para explorar y la regla de actualizaciÃ³n de **Q-Learning**:

```
Q(s,a) â† Q(s,a) + Î± [ r + Î³ max_a' Q(s',a') âˆ’ Q(s,a) ]
```

## ğŸ’¾ Persistencia del modelo
- Guarda el modelo con **"Guardar modelo"** (genera `q_table.json`).
- CÃ¡rgalo con **"Cargar modelo"** para continuar mÃ¡s tarde.

## ğŸ“œ Licencia
MIT â€” Ãºsalo libremente en clases, demos y talleres.
